# Jetstream v1.5 Release Notes

# Major notes

## Pipelines command

Jetstream now includes the `jetstream pipelines` command. Pipelines are another 
layer added to managing workflow templates. Since templates support 
import/include/extend statements with Jinja, they can actually be modularized 
across several files. The pipeline system helps organize complicated templates 
with a few helpful features.

Pipelines are Jetstream templates that have been documented with version
information and added to a jetstream pipelines directory. This command allows 
pipelines to be referenced by name when starting runs and automatically 
includes any pipeline scripts and variables during process.

To create a pipeline:

Add the template file(s) to a directory that is in your pipelines searchpath. 
The default searchpath is your user home directoy, but it can be changed in the 
application settings (see jetstream settings -h)

Create a pipeline.yaml file in the directory and be sure to include the 
required fields.


### Pipelines allow templates to be referenced by a name and optional version

Have a template that you use all the time? Name it, document it, and then you
can use `jetstream pipelines` to start runs with the name. It's also 
version-aware, so you can reference a specific version of the pipeline, or just
let jetstream find the latest version that you have installed.


### Variables can be included in the `pipeline.yaml`

Pipelines can include constant data used for rendering the templates. For 
example, I use the `pipelines.yaml` to contain the file paths to reference data 
for Phoenix. This removes the need to repeat these paths throughout the 
template source code, and also brings those variables under our version control 
system (they used to be stored in files outside of the pipeline code).


### Additional executables/scripts can be included with the pipelines

If a `bin` property is added to the pipeline manifest, that directory will be
prepended to the user $PATH environment variable when the pipeline is started. 
It's a handy way to bundle additional scripts with a pipeline and have them 
all fall under the same project for version control purposes. 


## Tasks command updates

The tasks command was reworked internally, and there were some changes to the
cli options. The general philosophy for the command now is that a set of 
filters is used to select the tasks of interest by name or status. The task
names are now given as positional arguments, for example:

```
jetstream tasks bwa_mem_sample_A haplotypecaller_sample_A ...
```

These arguments allow for glob wildcard matching: `*` 

```
jetstream tasks bwa_mem_sample_*
```

Regex is also still supported:

```
jetstream tasks --regex 'bwa_mem_sample_[^A]' 
```

Finally, tasks matching the patterns can be filtered by status:

```
jetstream tasks -s complete bwa_mem_sample_*
```

By default, this command just lists any tasks matching the name/status options.
The action options can be used to perform additional actions on those tasks. 
For example, --verbose prints out a ton of information about each task matching
the query. 


### Template variables from command-line arguments

These options have changed (again...sorry), but this time I think they work 
really well. The reason for this change is to get rid of the awkward pattern 
of having to add the extra `--` argument before listing any config args. Also,
this new format is much easier to parse, and results in more informative error
messages when there are problems. Here are some use case examples:

Note: config variables can be added when creating projects (they will be stored
in the project.yaml) or when the pipeline/template is run (but they will not 
be saved in the project.yaml). I typically prefer to add variables when 
creating projects, because it means you can always go back later and see what
was used to render the template (in addition to seeing the final values used
in the commands themselves)

### Adding variables when creating a project:

Variables can be added one argument at a time

```
jetstream init myproject -c reference_path /path/to/reference/file
```

or multiple:

```
jetstream init myproject -c reference_path /path/to/reference/file -c email ryan@tgen.org
```

variables can have a type declared (string is default if no type is declared).
the type should be included with the key parameter, colon separated.

```
jetstream init myproject -c int:threads 8 -c str:email ryan@tgen.org
```


lots of variables can loaded from files (note upper-case C)

```
jetstream init myproject -C ~/myconfig.json
```


loading variables from multiple files is also supported, but you'll need to 
provide a name for them to be added under:

```
jetstream init myproject -c file:samples ~/mysamples.json -c file:patients ~/mypatients.json
```

Notice we used the lowercase `-c/--config`. Using uppercase `-C/--config-file`
overwrites the variable context entirely, and essentially adds the contents of
the file as "global" template variables. The lowercase `-c file:...` syntax
will include the variables loaded from the file under the namespace assigned
by the variable key.

JSON strings can also be loaded without saving to a file first:

```
jetstream init myproject -c json:names '["ryan", "bob", "fred"]' 
```


## Projects

Projects have seen a couple small improvements. The `project.yaml` and 
`config.yaml` have been collapsed into a single file: `project.yaml` with the 
previous contents of that file now being listed under the field `__project__`.
This minor change has big impacts for loading variable data, any information
about the project can now be introspected in templates with the `__project__` 
variable. 

Re-initializing projects with `jetstream init` command will update the 
`project.yaml` and will also add a record to the project history where you can
track changes to that file over time.

`jetstream project` has been improved and will tell you whats going on with a
project. 

# Minor changes

- Project `jetstream/pid.lock` file is now tracking pending runs on projects. 
  The `jetstream run` command will wait to acquire this file before starting.

- Template variables can no longer be stored in the user application settings 
  file. See more details in jetstream.templates

- Lots of unused code was removed, this really helped reduce the dependencies

- Task identity is only computed with `cmd` and `exec` directives. This means
  changes to cpus will not automatically cause a task to be re-run. In the 
  future this may be adjusted to include runtime options like container ids or
  conda envs. Related to next note:

- Workflow mash will always replace a task if the old version has failed. For
  example: If 99/100 tasks passed, one failed due to memory requirements. When 
  you update the `mem` directive, only the failed task would be replaced, the 
  other 99 tasks do not need to be run since the `cmd` hasn't changed.

- input/after/before directives cannot be mappings with an `re:` property any
  more. Instead, use the new pattern directives `after-re:` `before-re:` and
  `input-re`. This fixes a number of issues when creating graphs. 




