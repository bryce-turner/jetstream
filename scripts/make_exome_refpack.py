#!/usr/bin/env python3
"""WARNING: Your targets/baits files may need pre-processing!

    The intervals here should be compatible with the reference you are planning
    to use. That means the sequence names (first column) must match the refdict
    sequence names (SN field). AND The start/stop coordinates must fall
    inside the sequence lengths described by the refdict (LN field).

    Additionally, padding is added to the targets when creating the filter
    files. It is not included in the Picard metrics files. The targets intervals
    do NOT need to be padded before starting this process.

Summary:

The goal of this script is to generate the files needed to add a new capture
kit to the TGen pipeline. Three types of files will need to be created:

    Picard .interval_list

    These are used for Picard metrics modules and describe the locations
    targetted by the capture kit. Coverage metrics generated by the pipeline
    will be relative to the regions defined in these files. There is one
    '.interval_list' for the targets and one for the baits. If baits is
    not given, both files will be generated from the targets.
    https://gatkforums.broadinstitute.org/gatk/discussion/1319/collected-faqs-about-interval-lists
    http://broadinstitute.github.io/picard/command-line-overview.html#BedToIntervalList


    VCF merger filter .bed

    This is a bed file that describes the locations to include in the final
    merged VCF. This file is generated by extending the regions in the targets
    intervals file for a more comprehensive filter. This file is a union
    of the following intervals:

        A) Target intervals file padded by 100bp
        B) All exonic intervals (taken from the reference GTF) that
        intersect any interval in "A"


    CNA index .bed

    This file is an index for tCoNut, in bed format, which describes the
    targeted regions in 100bp intervals. This is generated by intersecting
    a template bed file with the VCF merger filter .bed. The result is an
    index file that describes the locations covered by the kit in 100bp
    increments.



Glossary:

    Targets

    Also called "regions" or "target regions". This is a file that describes the
    regions that the exome kit aims to capture. This is usually distributed by
    the manufacturer of the kit as a .bed file. It may need some pre-processing
    before starting this application.

    https://www.ensembl.org/info/website/upload/bed.html

    Baits

    Also called "probes". This is a file that describes the hybrid capture
    probes in the kit. This is usually distributed by the manufacturer of the
    kit as a .bed file. It may need some pre-processing before starting this
    application.


"""
import argparse
import logging
import os
import shutil
import subprocess

import pkg_resources
import tempstore

import jetstream
from jetstream.utils.formats.refdict import refdict_to_bedtools_genome
from jetstream.utils.formats import intervals

log = logging.getLogger(__name__)

CNA_TEMPLATE = '/home/tgenref/binaries/capture_specific_jetstream_file_creatio'\
               'n/Copy_Number_100bp_Interval_Template.bed'

KNOWN_SV = '/home/tgenref/homo_sapiens/grch37_hg19/hs37d5/tool_specific_re' \
             'sources/tconut/nonmatched_tumor_normal/NA12878_specific/Merged' \
             '_SV_DGV_1kg.bed'

PICARD_PATH = pkg_resources.resource_filename('jetstream', 'etc/picard.jar')

BEDTOOLS_PATH = 'bedtools'
# TODO im stumped how to add bedtools source in,
# maybe it needs to be built first and then distributed with a bdist? In that
# case we'll need to create setup a build tool/script for the project and it
# adds some complexity to the development process.


def arg_parser():
    parser = argparse.ArgumentParser(
        formatter_class=argparse.RawTextHelpFormatter,
        description='Generate a reference pack for a new exome kit. See epilog '
                    'for detailed usage instructions.',
        epilog=__doc__
    )

    parser.add_argument(
        '-t', '--targets',
        required=True,
        help='Path to the targets bed file.'
    )

    parser.add_argument(
        '-b', '--baits',
        help='Path to a baits bed file. This file is optional.'
      )

    parser.add_argument(
        '-g', '--gtf',
        required=True,
        help='Path to a reference GTF'
    )

    parser.add_argument(
        '-r', '--refdict',
        required=True,
        help='Path to the reference dictionary'
    )

    parser.add_argument(
        '-c', '--cna-template',
        default=CNA_TEMPLATE,
        help='Path to the CNA template bed file. [{}]'.format(CNA_TEMPLATE)
        # TODO: This should be replaced in the future with code that
        # that generates the template from a given refdict
    )

    parser.add_argument(
        '-k', '--known-sv',
        default=KNOWN_SV,
        help='Path to the known SVs bed file. [{}]'.format(KNOWN_SV)
    )

    parser.add_argument(
        '--save-temp', action='store_true', default=False,
        help='Also saves all temp files created during the process'
    )

    return parser


def check_java_version():
    ver = subprocess.check_output(
        ['java', '-version'],
        stderr=subprocess.STDOUT
    ).decode()
    return ver


def external_proc(cmd_args, out_path):
    """Launch external process that writes to out_path"""
    cmd_string = ' '.join(cmd_args)
    log.critical('Starting external process: {}'.format(cmd_string))

    with open(out_path, 'w') as fp:
        p = subprocess.Popen(cmd_args, stdout=fp)
        p.wait()

    if p.returncode != 0:
        raise ChildProcessError(cmd_string)

    return p.returncode


def picard_bedtointervallist(bed, refdict, out_path):
    """Starts a Picard BedToIntervalList process that writes to out_path"""
    log.critical(check_java_version())

    cmd_args = [
        'java',
        '-jar',
        PICARD_PATH,
        'BedToIntervalList',
        'I=' + bed,
        'O=/dev/stdout',
        'SD=' + refdict,
    ]

    log.debug('Starting Picard: {}'.format(' '.join(cmd_args)))
    return external_proc(cmd_args, out_path)


def bedtools_intersect(a, b, out_path):
    """ Writes bedfile to out_path that includes all intervals in a which
    intersect any interval in b. """
    cmd_args = [
        BEDTOOLS_PATH,
        'intersect',
        '-header',
        '-wa',
        '-a', a,
        '-b', b
    ]

    return external_proc(cmd_args, out_path)



def bedtools_intersect_v(a, b, out_path):
    cmd_args = [
        BEDTOOLS_PATH,
        'intersect',
        '-header',
        '-v',
        '-a', a,
        '-b', b
    ]

    return external_proc(cmd_args, out_path)


def bedtools_slop(bed, genome, out_path, b=100):
    """ bed can be path to a BED/GFF/VCF """
    cmd_args = [
        BEDTOOLS_PATH,
        'slop',
        '-b', str(b),
        '-header',
        '-i', bed,
        '-g', genome
    ]

    return external_proc(cmd_args, out_path)


def bedtools_merge(a, out_path):
    """Starts a bedtools sort and bedtools merge process, writes to out_path"""
    cmd_args_sort = [
        BEDTOOLS_PATH,
        'sort',
        '-header',
        '-i', a
    ]

    log.debug('Starting external process: {}'.format(' '.join(cmd_args_sort)))

    bedtools_sort = subprocess.Popen(cmd_args_sort, stdout=subprocess.PIPE)

    cmd_args = [
        BEDTOOLS_PATH,
        'merge',
        '-header',
        '-i', 'stdin'
    ]

    log.debug('Starting external process: {}'.format(' '.join(cmd_args)))

    with open(out_path, 'w') as fp:
        bedtools = subprocess.Popen(
            cmd_args,
            stdout=fp,
            stdin=bedtools_sort.stdout)
        bedtools.wait()

    if bedtools.returncode != 0:
        raise ChildProcessError(' '.join(bedtools.args))

    return bedtools.returncode


def gtf_to_bed(gtf_path, out_path):
    ints = intervals.read_gffv2(gtf_path)
    ints = ints.filter(lambda i: i['feature'] == 'exon')  # Select only exons

    with open(out_path, 'w') as fp:
        fp.write(intervals.to_bed(ints))


def make_vcf_filter(targets, refdict, gtf, out_path):
    # A: Make an exon bed file from the GTF
    gtf_to_bed(gtf, out_path=TEMPFILES.create('exons.bed'))

    # B: Make padded bed for generating filter files
    # First create a "bedtools genome" file from the refdict
    refdict_to_bedtools_genome(
        refdict,
        out_path=TEMPFILES.create('refdict.genome')
    )

    # Now pad the targets file
    bedtools_slop(
        bed=targets,
        genome=TEMPFILES.paths['refdict.genome'],
        b=100,
        out_path=TEMPFILES.create('padded100_targets.bed')
    )

    # C: Intersect A and B, keep A
    # This keeps only those exons which intersect a target in the
    # padded targets file
    bedtools_intersect(
        a=TEMPFILES.paths['exons.bed'],
        b=TEMPFILES.paths['padded100_targets.bed'],
        out_path=TEMPFILES.create('captured_exons.bed')
    )

    # D: Generate Union of A and C
    # Create a new file to store all the ints
    all_ints_path = TEMPFILES.create('all_intervals.bed')
    with open(all_ints_path, 'w') as ai:

        # Write padded100_targets
        with open(TEMPFILES.paths['padded100_targets.bed'], 'r') as pt:
            for line in pt:
                ai.write(line)

        # And write captured exons
        with open(TEMPFILES.paths['captured_exons.bed'], 'r') as ce:
            for line in ce:
                ai.write(line)

    # Finally, merge all the intervals in all_intervals and return
    bedtools_merge(
        a=TEMPFILES.paths['all_intervals.bed'],
        out_path=out_path
    )

    return out_path


def make_cna_index(bed_path, cna_template_bed, out_path, x='23', y='24'):
    """Generates a CNA index from template and filter bed files."""
    bed = intervals.read_bed(bed_path)

    # First we need to chang X Y to integers in order to match template
    for i in bed:
        if i['seqname'] == 'X':
            i['seqname'] = x
        elif i['seqname'] == 'Y':
            i['seqname'] = y

    tmp_bed_path = TEMPFILES.create(bed_path + '_temp_23_24.bed')
    with open(tmp_bed_path, 'w') as fp:
        print(intervals.to_bed(bed), file=fp)

    cmd_args = [
        BEDTOOLS_PATH,
        'intersect',
        '-header',
        '-c',
        '-a', cna_template_bed,
        '-b', tmp_bed_path
    ]

    return external_proc(cmd_args, out_path=out_path)


def make_unmatched_cna_index(intervals, known_sv, cna_template_bed, out_path):
    ints_not_in_sv = TEMPFILES.create('ints_not_in_sv.bed')
    bedtools_intersect_v(
        a=intervals,
        b=known_sv,
        out_path=ints_not_in_sv
    )
    return make_cna_index(
        bed_path=ints_not_in_sv,
        cna_template_bed=cna_template_bed,
        out_path=out_path
    )


def save_results(targets_path, baits_path, save_temp):
    # Save the targets.interval_list
    targets_base = os.path.basename(targets_path)
    targets_root, targets_ext = os.path.splitext(targets_base)
    out_path = targets_root + '.interval_list'

    log.critical("Saving targets.intervals_list to {}".format(out_path))
    shutil.copy(TEMPFILES.paths['targets.interval_list'], out_path)

    # Save the baits.interval_list if it was created
    if baits_path is not None:
        baits_base = os.path.basename(baits_path)
        baits_root, baits_ext = os.path.splitext(baits_base)
        out_path = baits_root + '.interval_list'

        log.critical("Saving baits.interval_list to {}".format(out_path))
        shutil.copy(TEMPFILES.paths['baits.interval_list'], out_path)

    # Save VCF filter bed file
    out_path = targets_root + '.filter.bed'
    log.critical("Saving vcf_filter.bed to {}".format(out_path))
    shutil.copy(TEMPFILES.paths['vcf_filter.bed'], out_path)

    # Save CNA bed file
    out_path = targets_root + '.cna.bed'
    log.critical("Saving cna_index.bed to {}".format(out_path))
    shutil.copy(TEMPFILES.paths['cna_index.bed'], out_path)

    # Save Unmatched CNA bed file
    out_path = targets_root + '.unmatched_cna.bed'
    log.critical("Saving unmatched_cna_index.bed")
    shutil.copy(TEMPFILES.paths['unmatched_cna_index.bed'], out_path)

    if save_temp:
        log.critical("Saving all tempfiles {}".format(TEMPFILES.paths))
        TEMPFILES.copy('./', exist_ok=True)
    return


def main(args=None):
    parser = arg_parser()
    args = parser.parse_args(args)
    log.critical(jetstream.utils.fingerprint(to_json=True))
    log.critical(args)


    # Make Picard targets/baits interval list files
    picard_bedtointervallist(
        bed=args.targets,
        refdict=args.refdict,
        out_path=TEMPFILES.create('targets.interval_list')
    )
    if args.baits is not None:
        picard_bedtointervallist(
            bed=args.baits,
            refdict=args.refdict,
            out_path=TEMPFILES.create('baits.interval_list')
        )


    # Make VCF bed file
    make_vcf_filter(
        targets=args.targets,
        refdict=args.refdict,
        gtf=args.gtf,
        out_path=TEMPFILES.create('vcf_filter.bed')
    )


    # Make CNA index bed file
    make_cna_index(
        bed_path=TEMPFILES.paths['vcf_filter.bed'],
        cna_template_bed=args.cna_template,
        out_path=TEMPFILES.create('cna_index.bed')
    )


    # Make unmatched CNA index bed file
    make_unmatched_cna_index(
        intervals=TEMPFILES.paths['vcf_filter.bed'],
        known_sv=args.known_sv,
        cna_template_bed=args.cna_template,
        out_path=TEMPFILES.create('unmatched_cna_index.bed')
    )


    # Now save results to the cwd
    save_results(args.targets, args.baits, args.save_temp)


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.DEBUG,
        format="[%(asctime)s] %(message)s",
        handlers=[logging.FileHandler("log.txt"), logging.StreamHandler()]
    )

    TEMPFILES = tempstore.TempStore(name='temp')

    try:
        main()
    finally:
        TEMPFILES.cleanup()
